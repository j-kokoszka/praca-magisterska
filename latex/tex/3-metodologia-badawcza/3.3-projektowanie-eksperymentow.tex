%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Projektowanie eksperymentów}
Projektowanie eksperymentów stanowi kluczowy etap niniejszej pracy magisterskiej, mający 
na celu systematyczną i powtarzalną weryfikację postawionych hipotez oraz udzielenie 
odpowiedzi na zdefiniowane problemy badawcze. Celem jest obiektywna ocena wydajności, 
efektywności oraz zachowania autonomicznych mechanizmów skalowania w środowisku Kubernetes. 
Eksperymenty zostaną zaprojektowane tak, aby umożliwić bezpośrednie porównanie działania 
istniejących rozwiązań (VPA, HPA, KEDA) z autorskim podejściem opartym na modelu MAPE-K, 
w kontrolowanych warunkach obciążenia.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Wybór metryk oceny}
Aby rzetelnie ocenić skuteczność poszczególnych mechanizmów autoskalowania, konieczny jest 
precyzyjny wybór obiektywnych i mierzalnych metryk. W ramach niniejszych badań zostaną 
uwzględnione następujące kategorie metryk, które pozwolą na wieloaspektową analizę:

\begin{enumerate}
    \item \textbf{Metryki efektywności wykorzystania zasobów:}
    \begin{itemize}
        \item \textbf{Średnie i maksymalne zużycie CPU (\%):} Procentowe wykorzystanie 
        procesora przez Pody w stosunku do przydzielonych im zasobów. Wysokie zużycie 
        przy niskim marginesie błędu świadczy o efektywnym wykorzystaniu.
        \item \textbf{Średnie i maksymalne zużycie pamięci (MiB/\%):} Analogicznie, pomiar 
        wykorzystania pamięci.
        \item \textbf{Współczynnik marnotrawstwa zasobów (\%):} Obliczony jako stosunek 
        niewykorzystanych, ale przydzielonych zasobów do całkowitej ilości przydzielonych 
        zasobów. Niższy współczynnik wskazuje na lepszą optymalizację.
        \item \textbf{Liczba alokowanych vs. faktycznie wykorzystanych zasobów:} Analiza 
        różnic między zasobami żądanymi (requests) i limitowanymi (limits) a rzeczywistym 
        zużyciem.
    \end{itemize}
    \item \textbf{Metryki wydajności usług (Quality of Service - QoS):}
    \begin{itemize}
        \item \textbf{Średni i maksymalny czas odpowiedzi (Response Time - RT):} Mierzone 
        w milisekundach, od momentu wysłania żądania do otrzymania odpowiedzi. Niższy czas 
        odpowiedzi wskazuje na lepszą responsywność.
        \item \textbf{Przepustowość (Throughput):} Liczba zrealizowanych operacji 
        (np. żądań HTTP) na jednostkę czasu. Wyższa przepustowość oznacza większą zdolność 
        systemu do obsługi obciążenia.
        \item \textbf{Wskaźnik błędów (\%):} Procent nieudanych żądań lub operacji w stosunku 
        do całkowitej liczby. Niższy wskaźnik świadczy o stabilności.
        \item \textbf{P95/P99 czasu odpowiedzi:} 95. i 99. percentyl czasu odpowiedzi, 
        wskazujący na doświadczenia większości użytkowników i skalę problemów dla marginalnej 
        grupy.
    \end{itemize}
    \item \textbf{Metryki operacyjne i stabilności:}
    \begin{itemize}
        \item \textbf{Liczba skalowań (up/down):} Częstotliwość zmian liczby replik lub 
        zasobów, co może świadczyć o stabilności lub "chwiejności" autoskalera.
        \item \textbf{Liczba restartów Podów:} Dotyczy VPA, gdzie zmiana zasobów może wymagać 
        restartu, co wpływa na dostępność.
        \item \textbf{Czas stabilizacji po zmianie obciążenia:} Czas potrzebny systemowi na 
        osiągnięcie stabilnego stanu (np. powrót metryk do pożądanych wartości) po gwałtownej 
        zmianie obciążenia.
    \end{itemize}
\end{enumerate}
Zebrane dane zostaną poddane analizie statystycznej w celu wyciągnięcia wiarygodnych wniosków.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Scenariusze obciążenia i symulacje}
Aby zapewnić kompleksową ocenę i porównanie mechanizmów skalowania, eksperymenty zostaną 
przeprowadzone z wykorzystaniem różnorodnych, realistycznych \textbf{scenariuszy obciążenia}. 
Scenariusze te mają za zadanie odzwierciedlać typowe wzorce ruchu występujące w rzeczywistych 
środowiskach produkcyjnych, a także testować odporność systemów na nagłe i ekstremalne zmiany. 
Planuje się zastosowanie następujących typów obciążenia:

\begin{itemize}
    \item \textbf{Obciążenie stałe (Constant Load):} Utrzymywanie stabilnego, umiarkowanego 
    obciążenia przez dłuższy czas, w celu oceny efektywności bazowej alokacji zasobów i 
    stabilności działania autoskalerów.
    \item \textbf{Obciążenie narastające (Ramp-up Load):} Stopniowe zwiększanie obciążenia, 
    aby zbadać zdolność autoskalerów do adaptacji i skalowania w górę w miarę wzrostu 
    zapotrzebowania.
    \item \textbf{Obciążenie szczytowe (Peak Load):} Gwałtowny i wysoki wzrost obciążenia 
    (tzw. "spike"), mający na celu przetestowanie szybkości reakcji i odporności mechanizmów 
    na nagłe, intensywne zapotrzebowanie.
    \item \textbf{Obciążenie zmienne cyklicznie (Cyclic/Diurnal Load):} Symulacja wzorców 
    ruchu charakterystycznych dla cykli dobowych lub tygodniowych (np. niższe obciążenie w 
    nocy, wyższe w ciągu dnia), w celu oceny zdolności autoskalerów do efektywnego skalowania 
    zarówno w górę, jak i w dół.
    \item \textbf{Obciążenie ze zmiennymi wzorcami dostępu (Varying Access Patterns):} 
    Złożone scenariusze, które mogą symulować różne typy operacji (np. odczyty vs. zapisy 
    w bazie danych), aby ocenić, jak mechanizmy radzą sobie z różnorodnym zapotrzebowaniem 
    na zasoby.
\end{itemize}
Każdy scenariusz zostanie powtórzony wielokrotnie w celu zapewnienia wiarygodności 
statystycznej wyników.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Narzędzia i środowisko eksperymentalne}
Przeprowadzenie rzetelnych eksperymentów wymaga odpowiednio skonfigurowanego środowiska testowego 
oraz zestawu narzędzi. W niniejszej pracy zostanie wykorzystany następujący zestaw zasobów:

\paragraph{Obciążana usługa testowa}
\hfill\\
Obciążana usługa testowa została zaimplementowana w języku Python z wykorzystaniem frameworka 
\textbf{FastAPI}. Jej głównym zadaniem jest symulowanie zróżnicowanych scenariuszy zużycia 
zasobów, niezbędnych do weryfikacji funkcjonalności mechanizmów automatycznego skalowania
(w tym VPA, HPA, KEDA oraz Operatora MAPE-K). Aplikacja udostępnia trzy dedykowane punkty 
końcowe (endpointy), z których każdy symuluje inny typ obciążenia:

\begin{itemize}
    \item \textbf{\texttt{/cpu}}: Symuluje obciążenie \textit{CPU-bound} (zależne od procesora) 
    poprzez wykonywanie operacji haszujących (\texttt{hashlib.sha256}).
    \item \textbf{\texttt{/mem}}: Symuluje obciążenie \textit{Memory-bound} (związane z 
    pamięcią operacyjną) poprzez dynamiczną alokację dużych tablic (\texttt{numpy}).
    \item \textbf{\texttt{/io}}: Symuluje obciążenie \textit{I/O-bound} (wejścia/wyjścia) 
    poprzez operacje zapisu i odczytu plików tymczasowych.
\end{itemize}

Poprzez zmianę parametrów przekazywanych w żądaniach HTTP do tych endpointów, możliwe jest 
precyzyjne kontrolowanie intensywności obciążenia klastra. Ponadto, aplikacja posiada 
wbudowaną instrumentację (\texttt{prometheus-fastapi-instrumentator}), która automatycznie 
wystawia metryki wydajnościowe. Metryki te są zbierane przez system monitorujący klastra, 
stanowiąc kluczowe dane wejściowe dla wszystkich testowanych metod automatycznego skalowania.

\paragraph{Generator ruchu k6}
\hfill\\
Jako generator ruchu sieciowego i narzędzie do przeprowadzania testów wydajnościowych 
wykorzystano \textbf{k6}. Jest to narzędzie \textit{open source}, które pozwala na 
definiowanie skomplikowanych scenariuszy testowych w języku JavaScript.

Kluczową cechą metodologiczną jest fakt, że \textbf{skrypty testowe k6 są uruchamiane lokalnie 
z konsoli} na stanowisku roboczym. Generowane przez nie żądania HTTP kierowane są na zewnętrzny 
adres klastra Kubernetes (przez serwis typu \texttt{LoadBalancer}), co realistycznie symuluje 
ruch pochodzący od zewnętrznych użytkowników. Taka konfiguracja umożliwia pomiar kluczowych 
metryk (np. opóźnienia \textit{latency}) z perspektywy klienta, zapewniając wiarygodność 
danych wyjściowych testów porównawczych.

\paragraph{Środowisko eksperymentalne (klaster Kubernetes)}
\hfill\\
Szczegółowa specyfikacja klastra Kubernetes, w tym parametry maszyn wirtualnych, system 
operacyjny oraz narzędzia do zarządzania infrastrukturą (\textbf{Terraform}, \textbf{Ansible}, 
\textbf{FluxCD}), zostały opisane w podrozdziałach \texttt{3.2.1} i \texttt{3.2.2}. Na potrzeby 
eksperymentów w tym środowisku wdrożono również kompletny stos monitorujący (\textbf{Prometheus}, 
\textbf{Grafana}), który służy zarówno do zasilania pętli Operatora MAPE-K, jak i jako główne 
narzędzie do analizy danych i wizualizacji wyników porównawczych wszystkich testowanych 
mechanizmów skalowania (VPA, HPA, KEDA).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Analiza Wrażliwości i Narzut Systemowy (Overhead)}

Weryfikacja efektywności autonomicznej pętli sterującej wymaga nie tylko pomiaru zysków w zakresie wydajności (\textit{Service Level Objectives - SLO}) i optymalizacji kosztów, lecz także krytycznej analizy narzutu systemowego (\textit{overhead}) generowanego przez sam mechanizm monitorowania i sterowania. Agresywne nastawy pętli, w szczególności interwał odpytywania metryk (\textit{polling rate}) ustawiony na $1\,\text{s}$ (w przypadku \texttt{KEDA} i \texttt{Prometheus}), stanowią kluczowy czynnik ryzyka, wprowadzający potencjalną niestabilność i przeciążenie.

Narzut systemowy, $\mathcal{O}_{\text{MAPE-K}}$, definiowany jest jako zużycie zasobów klastra, które jest bezpośrednim skutkiem działania pętli sterującej, a nie obciążenia aplikacyjnego. W ramach pracy wyodrębniono trzy główne wektory generowania narzutu przy wysokiej częstotliwości próbkowania:

\begin{enumerate}
    \item \textbf{Saturacja Warstwy Sterowania (\textit{Control Plane Saturation}):} Częste zapytania (\texttt{GET/LIST} zasobów \texttt{CustomResourceDefinitions} oraz statusów \texttt{HPA/Deployment}) do \texttt{kube-apiserver} i \texttt{etcd}. Jest to najbardziej krytyczny punkt obciążenia, prowadzący do dławienia (\textit{throttling}) pozostałych żądań administracyjnych.
    \item \textbf{Koszty Infrastruktury Monitorującej:} Wzrost zużycia CPU i pamięci RAM przez komponenty takie jak \texttt{Prometheus} (ze względu na konieczność parsowania, indeksowania i zapisu dużej liczby próbek na sekundę) oraz operatorzy skalujący (\texttt{KEDA Operator}).
    \item \textbf{Narzut Aplikacyjny i Sieciowy:} Konieczność częstego generowania i serializacji metryk wewnątrz aplikacji (endpoint \texttt{/metrics}), co w systemach jednowątkowych może prowadzić do wzrostu opóźnień (\textit{latency}) w obsłudze ruchu biznesowego.
\end{enumerate}

Do pomiaru narzutu systemowego wykorzystano zestaw metryk bazujących na systemach monitorujących klastra Kubernetes:
\begin{itemize}
    \item \textbf{Zużycie CPU/RAM \texttt{kube-apiserver}:} Monitorowane za pomocą metryk \texttt{kube\_pod\_container\_resource\_limits} oraz \texttt{usage\_seconds\_total}.
    \item \textbf{Współczynnik Dławienia (\textit{Throttling Rate}):} Wzrost liczby błędów \texttt{429 (Too Many Requests)} w metryce \texttt{apiserver\_request\_total}.
    \item \textbf{Opóźnienie etcd:} Analiza metryki \texttt{etcd\_disk\_wal\_fsync\_duration\_seconds} jako wskaźnika wydajności persystencji danych klastra.
\end{itemize}


W celu wyznaczenia opłacalności stosowania agresywnego próbkowania przeprowadzono test A/B, porównując dwie konfiguracje pętli sterującej przy identycznym obciążeniu syntetycznym:

\begin{itemize}
    \item \textbf{Scenariusz A (Baseline):} \texttt{Polling Rate} $= 30\,\text{s}$ (Standardowy).
    \item \textbf{Scenariusz B (Real-time):} \texttt{Polling Rate} $= 1\,\text{s}$ (Agresywny).
\end{itemize}
Wyniki testu umożliwią określenie punktu, w którym narzut $\mathcal{O}_{\text{MAPE-K}}$ staje się istotny, a dalsze zwiększanie częstotliwości próbkowania przestaje przynosić korzyści w stabilizacji wydajności aplikacji.
